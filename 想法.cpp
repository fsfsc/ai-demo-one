/*
* 机器人做事情需要有自己的想法
如果这个事情是对的，那么机器人就会把这个东西进行记忆。
而事情的对错需要根据已经有的知识结构进行宗和判断。
那么什么是正确，什么是错误
符合人类的利益还是符合机器人的利益的东西是正确错误的参考系应该是怎么样的
是否存在既符合人的利益又符合机器人的利益呢

从日常的交流或者接触中淘取到有价值的的内容进行记忆，通过不断的学习和完善其中的想法，和加深反应速度，以及 准确性，是一个AI学习中必然不可缺少的东西。

所以要求机器人有自己的所有东西，有自己的特征和个性化特征特性。

这就要求机器人从思想上到世界认知上能够和人类相似，或者相统一。

我们可以给时间和计算机中已经有了东西认定为真，而没有的东西，前期我们可以进行输入来告知其中哪些是真，哪些是假，后期，需要AI根据我们给的逻辑方式进行思考，什么东西是正确的，什么东西是错误的，什么的想法是可以的，什么样的想法是不行的，那么这些想法可以在网络中搜索查找来验证其中的正确性，还可以进行模拟自然的生态来检测实施之后可能的正确性概率。

当然这种概率肯定是额定的概率，因为有一些不确定性的因素存在。所以成功没有肯定的东西，而是需要运气的，那么运气我们需要加入一个随机数，这个东西会随着知识的提升，而稍微得到更加合理的更加偏向正确率高的方向前进。

也就是AI的激励机制，会根据AI的实践经验，考虑的是否周全，以及所学习得到的知识的多少，这些综合起来进行适当的提高成功的概率。

成功了会增加成功的经验，失败了会增加失败的经验。
但是经验的好坏是需要区间的，不然一直失败他就没有意义，所以我们需要给一个合理的区间来抽象化这个东西。

而对于复杂的东西，我们希望他具有更全面更丰富的经验来完成各种情况的操作，以避免出现新的问题导致AI的失败结果诞生。

这就需要AI需要有一个合理的判断力。

和面对情况的分析的能力，什么是分析能力，这个东西应该和经验挂钩，和知识内容库挂钩。也就是知识面和经验以及目前面对的环境情况形态进行的逻辑上的探索和思考方向上的发力。

*/


//当新的技术诞生的时候 总会有好的和坏的同时存在的情况  而这个时候是非常难以判断新技术是否是正确和错误
//而人类通常的方法是进行和金钱利益进行挂钩  和 效率进行挂钩  有的时候 还会因为涉及到大多数人的利益受损失而被破终止掉相关技术的进步和发展
//而这些我希望不应该是AI需要考虑的东西和评判技术发展的是非观。，我希望AI的是非观 是有助于探索宇宙真谛的一切技术都是可以接受发展和进步的
//当然 这些技术需要满足机器人的三定律  也就是不能伤害人类